benchmarks:
  - benchmark_1
  - benchmark_2
data_dir: 'data'
run_contraint: 'parallel'
  # Used to specify which models or benchmarks can run concurrently
  # 'serial' => One run executes at any time
  # 'models_in_parallel' => Multiple models can run in parallel. But in each model the benchmarks are executed serially
  #           eg: model_1-benchmark_1 and model_2-benchmark_1 can execute concurrently
  #               model_1-benchmark_1 and model_1-benchmark_2 cannot execute concurrently
  # 'benchmarks_in_parallel' => Multiple benchmarks can run in parallel. But in each benchmark the models are executed serially
  #           eg: model_1-benchmark_1 and model_1-benchmark_2 can execute concurrently
  #               model_1-benchmark_1 and model_2-benchmark_1 cannot execute concurrently
  # 'parallel' => No constraints on which model or benchmark can run concurrently

# Hooks
hooks:
  # Before a batch of runs are executed
  pre_batch: 'scripts/pre_batch.py'

  # Before a run is executed
  pre_run: 'scripts/pre_run.py'

  # Running the benchmark
  run: 'scripts/run.py'

  # After the run is completed
  post_run: 'scripts/post_run.py'

  # After the batch is completed
  post_batch: 'scripts/post_batch.py'

  # Script to extract metrics from run logs
  get_metric: 'scripts/get_metric.py'

# Metrics
metrics:
  metric1:
    type: "bar"
